from beanie import Document, PydanticObjectId, Link
from pydantic import BaseModel, EmailStr, Field
from typing import Optional, Any
from datetime import datetime, timezone, timedelta
from enum import Enum
from pymongo import IndexModel
from bson import ObjectId

# my imports 
from src.dtos import Dictor
from src.dtos import TaskTypes, TaskStatus, PdfEvents
from src.events import event_manager

#-----------------------
# User model
#-----------------------

# plane types -> for freemium
class PlanType(str, Enum):
  FREE = "free"
  STANDARD = 'standard'
  BRONZE = 'bronze'
  GOLD = "gold"

class User(Document):
  email: EmailStr
  name: str = Field(default="user") # some default value for the user 
  hashed_password: Optional[str] = None
  is_active: bool = True # for account deactivation

  # subscription info
  plan: PlanType = PlanType.FREE
  subscription_start: Optional[datetime] = None
  subscription_end: Optional[datetime] = None

  # usage stats -> for freemium limits
  total_pdfs_upload: int = 0
  total_pages_processes: int = 0 # pdf page processing
  total_tokens_used: int = 0 # embedding/chat

  # metadata
  created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
  updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

  class Settings:
    name  = 'users'# name of collection

  # methods 

#-----------------------
# Task model
#-----------------------

class Task(Document):
  task_type: TaskTypes
  status: TaskStatus = Field(default=TaskStatus.INCOMPLETE)
  payload: Dictor # dynamic data dictionary 
  retries: int = Field(default=0)
  max_retries: int = Field(default=5)
  error: Optional[str] = None

  created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
  updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
  completed_at: Optional[datetime] = None

  class Settings: 
    name = "tasks"

  async def mark_processing(self):
    """ mark a task processing by the worker """
    self.status = TaskStatus.PROCESSING
    self.updated_at = datetime.now(timezone.utc)
    await self.save()

  async def mark_done(self):
    """ mark a task as done, processed by the worker """
    self.status = TaskStatus.DONE
    self.completed_at = datetime.now(timezone.utc)
    self.updated_at = datetime.now(timezone.utc)
    await self.save()

  async def mark_failed(self, error_msg: str):
    """ 
     if: max_retries -> status = failed
     else: status = incomplete
    """

    self.error = error_msg
    self.retries += 1 # fails -> increment retry

    if self.retries < self.max_retries:
      # failed and done!
      self.status = TaskStatus.INCOMPLETE
    else:
      # still can try
      self.status = TaskStatus.FAILED
    
    self.updated_at = datetime.now(timezone.utc)
    await self.save()

#-----------------------
# Otp model
#-----------------------

# beanie orm
class Otp(Document):
  otp_code: str # required
  # await otp.user.fetch()
  user: Link[User] # reference to user doc

  # expiration
  #expires_at: datetime = datetime.now(timezone.utc) + timedelta(minutes=5) # 5 min
  expires_at: datetime = Field(
    default_factory=lambda: datetime.now(timezone.utc) + timedelta(minutes=5)
  )
  is_used: bool = False

  # metadata
  created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

  class Settings:
    name = "otps"
    
    # TTL index on expires_at field
    indexes: Any = [
      IndexModel([('expires_at', 1)], expireAfterSeconds=0),
    ]

  # methods

  def is_valid(self) -> bool:
    """ check otp is still valid (not expired , not used) """
    return not self.is_used and self.expires_at > datetime.now(timezone.utc)
  

#-----------------------
# Upload model
#-----------------------

from src.dtos import UploadStatus

class Upload(Document):
  #upload_id: str # uuid generated by the client
  user: Link[User]
  percent: int = 0 # upload progress
  status: UploadStatus = UploadStatus.UPLOADING # upload status
  # gridfs
  file_id: Optional[str] = None # file id
  error: Optional[str] = None
  filename: Optional[str] = None
  file_hash: str # unique file
  file_size: int

  created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
  updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

  class Settings:
    name = "uploads"
    # auto clean this -> after an hour
    # indexes = [
    #   IndexModel([('updated_at', 1)], expiresAfterSeconds=3600)
    # ]

from src.dtos import PDFStatus

# define a PDF model -> holds PDF metadata -> extracted text and html
class PDF(Document):
  title: Optional[str] = None
  filename: str # file.filename

  # reference to file in GridFs
  gridfs_id: str

  upload_id: str # SSE event
  num_pages: Optional[int] = None
  # metadata
  user: Link[User] # required

  # current processing status
  status: PDFStatus = PDFStatus.UPLOADED

  # extracted text
  text_content: Optional[str] = None
  # extracted html
  html_content: Optional[str] = None

  created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
  updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

  class Settings:
    name = "pdfs"

  async def set_status(
      self,
      new_status: PDFStatus,
      user_id: str,
      # message: 
  ) -> None:
    """ update the PDF status and timestamp """
    self.status = new_status
    self.updated_at = datetime.now(timezone.utc)

    await event_manager.publish(
      user_id=str(user_id),
      event=PdfEvents.PDF_STATUS_UPDATE.value,
      data=self.model_dump(mode="json"), # type: ignore
    )

    await self.save()

class PdfPage(Document):
  pdf: Link[PDF] # reference to PDF
  page_number: int
  text: str # page text
  html: str # page html
  snippet: str
  need_ocr: bool # some pdf pages are images
  user: Link[User]

  created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
  updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

  class Settings:
    name = "pdf_pages"